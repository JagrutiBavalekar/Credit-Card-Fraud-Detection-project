{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749efb3c-b2e8-4605-a397-9cb60322dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score, classification_report, confusion_matrix, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Title\n",
    "st.title('Bank Card Fraud Detection')\n",
    "\n",
    "\n",
    "# Read Data into a Dataframe\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "\n",
    "# --- 1 CHECKBOX ---\n",
    "# Print description of the initial data and shape\n",
    "if st.sidebar.checkbox('Show the initial data set'):\n",
    "    st.header(\"Understanding dataset\")\n",
    "\n",
    "    st.write('Initial data set: \\n', df)\n",
    "    st.write('Data decription: \\n', df.describe())\n",
    "    st.write('Shape of the dataframe: ',df.shape)\n",
    "    st.text('The dataset consists of 284,807 rows and 31 columns.\\nThere is no zero value in the data.')\n",
    "\n",
    "    st.header(\"Checking missing and outlier values\")\n",
    "\n",
    "    # Check missing values\n",
    "    st.write('Missing values: ', df.isnull().values.sum())\n",
    "\n",
    "    # Checking the number of missing values in each column\n",
    "    st.write('The number of missing values in each column: ', df.isnull().sum())\n",
    "\n",
    "    # Percentage of null values\n",
    "    percent_missing = (df.isnull().sum().sort_values(ascending = False) / len(df)) * 100\n",
    "    st.write('Percentage of null values: ', percent_missing)\n",
    "\n",
    "    # Check if there are any duplicate rows\n",
    "    st.write('Duplicate rows: ', df.duplicated(keep=False).sum())\n",
    "\n",
    "    # Delete duplicate rows\n",
    "    df = df.drop_duplicates() \n",
    "    st.write('Deleting duplicate rows was successful. This is a new data set:', df)\n",
    "# --- 1 CHECKBOX ---\n",
    "\n",
    "\n",
    "\n",
    "# --- 2 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Show the analysis'):\n",
    "    \n",
    "    fraud = df[df.Class == 1]\n",
    "    valid = df[df.Class == 0]\n",
    "\n",
    "    outlier_percentage=(df.Class.value_counts()[1]/df.Class.value_counts()[0])*100\n",
    "\n",
    "    st.header('Univariate analysis')\n",
    "\n",
    "    st.write('Fraud Cases: ', len(fraud))\n",
    "    st.write('Valid Cases: ', len(valid))\n",
    "    st.write('Compare the values for both transactions: \\n', df.groupby('Class').mean())\n",
    "    st.write('Fraudulent transactions are: %.3f%%'%outlier_percentage)\n",
    "\n",
    "\n",
    "    # Method to compute countplot of given dataframe parameters:\n",
    "    # - data(pd.Dataframe): Input Dataframe\n",
    "    # - feature(str): Feature in Dataframe\n",
    "    def countplot_data(data, feature):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.countplot(x=feature, data=data)\n",
    "        plt.show()\n",
    "\n",
    "    # Method to construct pairplot of the given feature wrt data parameters:\n",
    "    # - data(pd.DataFrame): Input Dataframe\n",
    "    # - feature1(str): First Feature for Pair Plot\n",
    "    # - feature2(str): Second Feature for Pair Plot\n",
    "    # - target: Target or Label (y)\n",
    "    def pairplot_data_grid(data, feature1, feature2, target):\n",
    "        sns.FacetGrid(data, hue=target).map(plt.scatter, feature1, feature2).add_legend()\n",
    "        plt.show()\n",
    "\n",
    "    st.subheader('Transaction ratio:')\n",
    "    st.pyplot(countplot_data(df, df.Class))\n",
    "\n",
    "    st.subheader('The relationship of fraudulent transactions with the amount of money:\\n')\n",
    "    st.pyplot(pairplot_data_grid(df, \"Time\", \"Amount\", \"Class\"))\n",
    "    \n",
    "\n",
    "\n",
    "    st.header('Bivariate Analysis')\n",
    "    \n",
    "    st.write('Fraud: ', df.Time[df.Class == 1].describe())\n",
    "    st.write('Not fraud: ', df.Time[df.Class == 0].describe())\n",
    "\n",
    "    \n",
    "    def graph1():\n",
    "        f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "        bins = 50\n",
    "\n",
    "        ax1.hist(df.Time[df.Class == 1], bins = bins)\n",
    "        ax1.set_title('Fraud')\n",
    "\n",
    "        ax2.hist(df.Time[df.Class == 0], bins = bins)\n",
    "        ax2.set_title('Not Fraud')\n",
    "\n",
    "        plt.xlabel('Time (Sec.)')\n",
    "        plt.ylabel('Number of Transactions')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def graph2():\n",
    "        f, axes = plt.subplots(ncols=2, figsize=(16,10))\n",
    "        colors = ['#C35617', '#FFDEAD']\n",
    "\n",
    "        sns.boxplot(x=\"Class\", y=\"Amount\", data=df, palette = colors, ax=axes[0], showfliers=True)\n",
    "        axes[0].set_title('Class vs Amount')\n",
    "\n",
    "        sns.boxplot(x=\"Class\", y=\"Amount\", data=df, palette = colors, ax=axes[1], showfliers=False)\n",
    "        axes[1].set_title('Class vs Amount without outliers')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def graph3():\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "        amount_val = df['Amount'].values\n",
    "        time_val = df['Time'].values\n",
    "\n",
    "        sns.distplot(amount_val, ax=ax[0], color='b')\n",
    "        ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "        ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "        sns.distplot(time_val, ax=ax[1], color='r')\n",
    "        ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "        ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    st.pyplot(graph1())\n",
    "    st.pyplot(graph2())\n",
    "    st.pyplot(graph3())\n",
    "\n",
    "\n",
    "\n",
    "    st.header('Multivariate Analysis')\n",
    "\n",
    "\n",
    "    # Plot relation with different scale\n",
    "    def graph4(): \n",
    "        df1 = df[df['Class']==1]\n",
    "        df2 = df[df['Class']==0]\n",
    "        fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "        ax[0].scatter(df1['Time'], df1['Amount'], color='red', marker= '*', label='Fraudrent')\n",
    "        ax[0].set_title('Time vs Amount')\n",
    "        ax[0].legend(bbox_to_anchor =(0.25, 1.15))\n",
    "\n",
    "        ax[1].scatter(df2['Time'], df2['Amount'], color='green', marker= '.', label='Non Fraudrent')\n",
    "        ax[1].set_title('Time vs Amount')\n",
    "        ax[1].legend(bbox_to_anchor =(0.3, 1.15))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def graph5():\n",
    "        sns.lmplot(x='Time', y='Amount', hue='Class', markers=['x', 'o'], data=df, height=6)\n",
    "    \n",
    "\n",
    "    # plot relation in same scale\n",
    "    def graph6():\n",
    "        g = sns.FacetGrid(df, col=\"Class\", height=6)\n",
    "        g.map(sns.scatterplot, \"Time\", \"Amount\", alpha=.7)\n",
    "        g.add_legend()\n",
    "    \n",
    "\n",
    "    st.pyplot(graph4())\n",
    "    st.pyplot(graph5())\n",
    "    st.pyplot(graph6())  \n",
    "# --- 2 CHECKBOX ---\n",
    "\n",
    "\n",
    "# --- 3 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Model building on imbalanced data'):\n",
    "    # --- TRAIN AND TEST SPLIT ---\n",
    "    st.header('Train and test split')\n",
    "\n",
    "\n",
    "    # Putting feature variables into X\n",
    "    X = df.drop(['Class'], axis=1)\n",
    "\n",
    "    # Putting target variable to y\n",
    "    y = df['Class']\n",
    "\n",
    "\n",
    "    # Splitting data into train and test set 80:20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    st.write('X_train: ', X_train.shape)\n",
    "    st.write('y_train: ', y_train.shape)\n",
    "    st.write('X_test: ', X_test.shape)\n",
    "    st.write('y_test: ', y_test.shape)\n",
    "    # --- TRAIN AND TEST SPLIT ---\n",
    "\n",
    "\n",
    "    \n",
    "    # --- FEATURE SCALING ---\n",
    "    # Instantiate the Scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the data into scaler and transform\n",
    "    X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])\n",
    "\n",
    "\n",
    "    # Transform the test set\n",
    "    X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
    "\n",
    "\n",
    "    # Checking the Skewness\n",
    "    # Listing the columns\n",
    "    cols = X_train.columns\n",
    "    \n",
    "    \n",
    "    # Plotting the distribution of the variables (skewness) of all the columns\n",
    "    def skewness(): \n",
    "        k = 0\n",
    "        plt.figure(figsize=(17,28))\n",
    "        for col in cols :    \n",
    "            k = k + 1\n",
    "            plt.subplot(6, 5,k)    \n",
    "            sns.distplot(X_train[col])\n",
    "            plt.title(col+' '+str(X_train[col].skew()))\n",
    "    \n",
    "\n",
    "    st.header('Checking the Skewness')\n",
    "    st.pyplot(skewness())\n",
    "    # --- FEATURE SCALING ---\n",
    "\n",
    "\n",
    "\n",
    "    # --- Mitigate skwenes with PowerTransformer ---\n",
    "    # Instantiate the powertransformer\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n",
    "\n",
    "    # Fit and transform the PT on training data\n",
    "    X_train[cols] = pt.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test set\n",
    "    X_test[cols] = pt.transform(X_test)\n",
    "\n",
    "    \n",
    "    def newSkewness():\n",
    "        k=0\n",
    "        plt.figure(figsize=(17,28))\n",
    "        for col in cols :    \n",
    "            k=k+1\n",
    "            plt.subplot(6, 5,k)    \n",
    "            sns.distplot(X_train[col])\n",
    "            plt.title(col+' '+str(X_train[col].skew()))\n",
    "    \n",
    "\n",
    "    st.header('Mitigate skwenes with PowerTransformer')\n",
    "    st.pyplot(newSkewness())\n",
    "    # --- Mitigate skwenes with PowerTransformer ---   \n",
    "# --- 3 CHECKBOX ---\n",
    "\n",
    "\n",
    "\n",
    "# --- 4 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Compare algorithms'):\n",
    "    # --- TRAIN AND TEST SPLIT ---\n",
    "    # Putting feature variables into X\n",
    "    X = df.drop(['Class'], axis=1)\n",
    "\n",
    "    # Putting target variable to y\n",
    "    y = df['Class']\n",
    "\n",
    "\n",
    "    # Splitting data into train and test set 80:20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "    # --- TRAIN AND TEST SPLIT ---\n",
    "\n",
    "\n",
    "    # --- FEATURE SCALING ---\n",
    "    # Instantiate the Scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    # Fit the data into scaler and transform\n",
    "    X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])\n",
    "\n",
    "\n",
    "    # Transform the test set\n",
    "    X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
    "\n",
    "\n",
    "    # Checking the Skewness\n",
    "    # Listing the columns\n",
    "    cols = X_train.columns\n",
    "    # --- FEATURE SCALING ---\n",
    "\n",
    "\n",
    "    # --- Mitigate skwenes with PowerTransformer ---\n",
    "    # Instantiate the powertransformer\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n",
    "\n",
    "    # Fit and transform the PT on training data\n",
    "    X_train[cols] = pt.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test set\n",
    "    X_test[cols] = pt.transform(X_test)\n",
    "    # --- Mitigate skwenes with PowerTransformer ---\n",
    "\n",
    "\n",
    "    def visualize_confusion_matrix(y_test, y_pred):\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Oranges',\n",
    "                    xticklabels=['No Credit Card Fraud Dection','Credit Card Fraud Dection'], \n",
    "                    yticklabels=['No Credit Card Fraud Dection','Credit Card Fraud Dection'])\n",
    "        plt.title('Accuracy: {0:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "        plt.ylabel('True Values')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.show()\n",
    "        \n",
    "        st.write(\"\\n\")\n",
    "        st.write(\"Classification Report:\")\n",
    "        st.text(classification_report(y_test, y_pred))\n",
    "        return\n",
    "\n",
    "    \n",
    "    def ROC_AUC(Y, Y_prob):\n",
    "        # caculate roc curves\n",
    "        fpr, tpr, threshold = roc_curve(Y, Y_prob)\n",
    "        # caculate scores\n",
    "        model_auc = roc_auc_score(Y, Y_prob)\n",
    "        # plot roc curve for the model\n",
    "        plt.figure(figsize=(16, 9))\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        plt.plot(fpr, tpr, marker='.', label='Model - AUC=%.3f' % (model_auc))\n",
    "        # show axis labels and the legend\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.show(block=False)\n",
    "        return\n",
    "\n",
    "\n",
    "    # --- START Logistic regression ---\n",
    "    st.header('Logistic Regression')\n",
    "    # --- START Training the Logistic Regression Model on the Training set ---\n",
    "    st.subheader('Training the Logistic Regression Model on the Training set')\n",
    "    \n",
    "\n",
    "    LR_model = LogisticRegression(random_state = 0)\n",
    "    LR_model.fit(X_train, y_train)\n",
    "    y_train_pred = LR_model.predict(X_train)\n",
    "    y_test_pred = LR_model.predict(X_test)\n",
    "    acc1 = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    # Train Score\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_train, y_train_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_train, y_train_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_train, y_train_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_train, y_train_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "    # Train Predictions\n",
    "    st.pyplot(visualize_confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_train, y_train_pred))\n",
    "    # --- END Training the Logistic Regression Model on the Training set ---\n",
    "\n",
    "\n",
    "    # --- START Training the Logistic Regression Model on the Testing set ---\n",
    "    st.subheader('Training the Logistic Regression Model on the Testing set')\n",
    "\n",
    "\n",
    "    # Test score\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_test, y_test_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_test, y_test_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_test, y_test_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_test, y_test_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    # Test Predictions\n",
    "    st.pyplot(visualize_confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_test, y_test_pred))\n",
    "    # --- END Training the Logistic Regression Model on the Testing set ---\n",
    "\n",
    "\n",
    "    # Result\n",
    "    st.header('Results')\n",
    "    st.subheader('Training set')\n",
    "    st.text('- Recall score: 0.6397\\n- Precision score: 0.8688\\n- F1-Score: 0.7368\\n- Accuracy score: 0.9992\\n- AUC: 0.8198')\n",
    "    \n",
    "\n",
    "    st.subheader('Testing set')\n",
    "    st.text('- Recall score: 0.5556\\n- Precision score: 0.9091\\n- F1-Score: 0.6897\\n- Accuracy score: 0.9992\\n- AUC: 0.7777')\n",
    "    # --- END Logistic regression ---\n",
    "\n",
    "\n",
    "\n",
    "    # --- START Naive Bayes ---\n",
    "    st.header('Naive Bayes')\n",
    "\n",
    "    \n",
    "    # --- START Training the Naive Bayes Model on the Training set ---\n",
    "    st.subheader('Training the Naive Bayes Model on the Training set')\n",
    "\n",
    "\n",
    "    NB_model = GaussianNB()\n",
    "    NB_model.fit(X_train, y_train)\n",
    "    y_train_pred = NB_model.predict(X_train)\n",
    "    y_test_pred = NB_model.predict(X_test)\n",
    "    acc2 = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    # Train Score\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_train, y_train_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_train, y_train_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_train, y_train_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_train, y_train_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "    # Train Predictions\n",
    "    st.pyplot(visualize_confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_train, y_train_pred))\n",
    "    # --- END Training the Naive Bayes Model on the Training set ---\n",
    "\n",
    "\n",
    "    # --- START Training the Naive Bayes Model on the Testing set ---\n",
    "    st.subheader('Training the Naive Bayes Model on the Testing set')\n",
    "\n",
    "\n",
    "    # Test score\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_test, y_test_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_test, y_test_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_test, y_test_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_test, y_test_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    # Test Predictions\n",
    "    st.pyplot(visualize_confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_test, y_test_pred))\n",
    "    # --- END Training the Naive Bayes Model on the Testing set ---\n",
    "\n",
    "\n",
    "    # Result\n",
    "    st.header('Results')\n",
    "    st.subheader('Training set')\n",
    "    st.text('- Recall score: 0.8277\\n- Precision score: 0.0604\\n- F1-Score: 0.1125\\n- Accuracy score: 0.9780\\n- AUC: 0.9030')\n",
    "    \n",
    "\n",
    "    st.subheader('Testing set')\n",
    "    st.text('- Recall score: 0.7778\\n- Precision score: 0.0523\\n- F1-Score: 0.0980\\n- Accuracy score: 0.9773\\n- AUC: 0.8777')\n",
    "    # --- END Naive Bayes ---\n",
    "\n",
    "    \n",
    "    \n",
    "    # --- START Decision tree ---\n",
    "    st.header('Decision tree')\n",
    "\n",
    "    \n",
    "    # --- START Training the Decision tree Model on the Training set ---\n",
    "    st.subheader('Training the Decision tree Model on the Training set')\n",
    "\n",
    "\n",
    "    DTR_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    DTR_model.fit(X_train, y_train)\n",
    "    y_train_pred = DTR_model.predict(X_train)\n",
    "    y_test_pred = DTR_model.predict(X_test)\n",
    "    acc4 = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    # Train Score\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_train, y_train_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_train, y_train_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_train, y_train_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_train, y_train_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(visualize_confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_train, y_train_pred))\n",
    "    # --- END Training the Decision tree Model on the Training set ---\n",
    "\n",
    "\n",
    "    # --- START Training the Decision tree Model on the Testing set ---\n",
    "    st.subheader('Training the Decision tree Model on the Testing set')\n",
    "\n",
    "\n",
    "    st.write('Recall score: %0.4f'% recall_score(y_test, y_test_pred))\n",
    "    st.write('Precision score: %0.4f'% precision_score(y_test, y_test_pred))\n",
    "    st.write('F1-Score: %0.4f'% f1_score(y_test, y_test_pred))\n",
    "    st.write('Accuracy score: %0.4f'% accuracy_score(y_test, y_test_pred))\n",
    "    st.write('AUC: %0.4f' % roc_auc_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    st.pyplot(visualize_confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "    st.pyplot(ROC_AUC(y_test, y_test_pred))\n",
    "    # --- END Training the Decision tree Model on the Testing set ---\n",
    "\n",
    "\n",
    "    # Result\n",
    "    st.header('Results')\n",
    "    st.subheader('Training set')\n",
    "    st.text('- Recall score: 1.0000\\n- Precision score: 1.0000\\n- F1-Score: 1.0000\\n- Accuracy score: 1.0000\\n- AUC: 1.0000')\n",
    "    \n",
    "\n",
    "    st.subheader('Testing set')\n",
    "    st.text('- Recall score: 0.6889\\n- Precision score: 0.7561\\n- F1-Score: 0.7209\\n- Accuracy score: 0.9992\\n- AUC: 0.8443')\n",
    "    # --- END Decision tree ---\n",
    "\n",
    "\n",
    "\n",
    "    st.header('Compare the accuracy of the models on the Testing set')\n",
    "\n",
    "    def compareResult():\n",
    "        mylist=[]\n",
    "        mylist2=[]\n",
    "\n",
    "        mylist.append(acc1)\n",
    "        mylist2.append(\"Logistic Regression\")\n",
    "\n",
    "        mylist.append(acc2)\n",
    "        mylist2.append(\"Naive Bayes\")\n",
    "\n",
    "        mylist.append(acc4)\n",
    "        mylist2.append(\"Decision Tree\")\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(22, 10))\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        ax = sns.barplot(x = mylist2, y = mylist, palette = \"Oranges\", saturation =1.5)\n",
    "        plt.xlabel(\"Classification Models\", fontsize = 20 )\n",
    "        plt.ylabel(\"Accuracy\", fontsize = 20)\n",
    "        plt.title(\"Accuracy of different Classification Models\", fontsize = 20)\n",
    "        plt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 0)\n",
    "        plt.yticks(fontsize = 13)\n",
    "        for p in ax.patches:\n",
    "            width, height = p.get_width(), p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    st.pyplot(compareResult())\n",
    "\n",
    "\n",
    "\n",
    "    st.header('ROC Curve and Area Under the Curve')\n",
    "\n",
    "\n",
    "    # Logistic Regression\n",
    "    y_pred_logistic = LR_model.predict_proba(X_test)[:,1]\n",
    "    logistic_fpr, logistic_tpr, threshold = roc_curve(y_test, y_pred_logistic)\n",
    "    auc_logistic = auc(logistic_fpr, logistic_tpr)\n",
    "\n",
    "\n",
    "    # Naive Bayes\n",
    "    y_pred_nb = NB_model.predict_proba(X_test)[:,1]\n",
    "    nb_fpr, nb_tpr, threshold = roc_curve(y_test, y_pred_nb)\n",
    "    auc_nb = auc(nb_fpr, nb_tpr)\n",
    "\n",
    "\n",
    "    # Decision Tree\n",
    "    y_pred_dtr = DTR_model.predict_proba(X_test)[:,1]\n",
    "    dtr_fpr, dtr_tpr, threshold = roc_curve(y_test, y_pred_dtr)\n",
    "    auc_dtr = auc(dtr_fpr, dtr_tpr)\n",
    "\n",
    "\n",
    "    def plottingGraphResultCompare():\n",
    "        plt.figure(figsize=(10, 8), dpi=100)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        # Logistic Regression\n",
    "        plt.plot(logistic_fpr, logistic_tpr, label='Logistic Regression (auc = %0.4f)' % auc_logistic)\n",
    "        # Naive Bayes\n",
    "        plt.plot(nb_fpr, nb_tpr, label='Naive Bayes (auc = %0.4f)' % auc_nb)\n",
    "\n",
    "        # Decision Tree\n",
    "        plt.plot(dtr_fpr, dtr_tpr, label='Decision Tree (auc = %0.4f)' % auc_dtr)\n",
    "\n",
    "\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    st.pyplot(plottingGraphResultCompare())\n",
    "\n",
    "# --- 4 CHECKBOX ---\n",
    "\n",
    "\n",
    "\n",
    "# --- 5 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Manual transaction verification'):\n",
    "\n",
    "    # separate legitimate and fraudulent transactions\n",
    "    legit = df[df.Class == 0]\n",
    "    fraud = df[df.Class == 1]\n",
    "\n",
    "    # undersample legitimate transactions to balance the classes\n",
    "    legit_sample = legit.sample(n=len(fraud), random_state=2)\n",
    "    data = pd.concat([legit_sample, fraud], axis=0)\n",
    "\n",
    "    # split data into training and testing sets\n",
    "    X = data.drop(columns=\"Class\", axis=1)\n",
    "    y = data[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)\n",
    "\n",
    "    # train logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate model performance\n",
    "    train_acc = accuracy_score(model.predict(X_train), y_train)\n",
    "    test_acc = accuracy_score(model.predict(X_test), y_test)\n",
    "\n",
    "    # create Streamlit app\n",
    "    st.title(\"Manual transaction verification\")\n",
    "    st.write(\"Enter the following features to check if the transaction is legitimate or fraudulent:\")\n",
    "\n",
    "    # create input fields for user to enter feature values\n",
    "    input_df = st.text_input('Input All features')\n",
    "    input_df_lst = input_df.split(',')\n",
    "    # create a button to submit input and get prediction\n",
    "    submit = st.button(\"Submit\")\n",
    "\n",
    "    if submit:\n",
    "        # get input feature values\n",
    "        features = np.array(input_df_lst, dtype=np.float64)\n",
    "        # make prediction\n",
    "        prediction = model.predict(features.reshape(1,-1))\n",
    "        # display result\n",
    "        if prediction[0] == 0:\n",
    "            st.write(\"Legitimate transaction\")\n",
    "        else:\n",
    "            st.write(\"Fraudulent transaction\")\n",
    "# --- 5 CHECKBOX ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
